# -*- coding: utf-8 -*-
"""predict_language.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mCjs4GJEhtl-zmRWfjp8Fjt5P4ZaVs9O
"""

# import necessary packages
import pandas as pd 
import numpy as np

from sklearn.preprocessing import LabelEncoder

import re
import time

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model.logistic import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.utils import shuffle
from sklearn.metrics import precision_score, classification_report, accuracy_score
from sklearn.pipeline import FeatureUnion

import warnings
warnings.filterwarnings("ignore")

"""**Data Preparation**"""

# load data
def load_data():
    file_name = './sampleCode.txt' # input code file
    data = open(file_name, 'r')
    lines = data.readlines()
    return lines

# clean data
def clean_data(input_code):
  
    #find all the code within the pre tags
    all_found = re.findall(r'<pre[\s\S]*?<\/pre>', input_code, re.MULTILINE)
    #print(all_found)
    
    #clean the unnecessary tags
    clean_string = lambda x: x.replace('&lt;', '<').replace('&gt;', '>').replace('</pre>', '').replace('\n', '')
    all_found = [clean_string(item) for item in all_found]
    #print(all_found)
    
    #get the language 
    get_language = lambda x: re.findall(r'<pre lang="(.*?)">', x, re.MULTILINE)[0]
    lang_items = [get_language(item) for item in all_found]
    #print(all_found)
    #print(lang_items)
    
    #remove all of the pre tags that contain the language
    remove_lang = lambda x: re.sub(r'<pre lang="(.*?)">', "", x)
    all_found = [remove_lang(item) for item in all_found]
    #print(all_found)
    
    #return the code between pre tags and their corresponding language
    return (all_found, lang_items)

all_samples = ''.join(load_data())
cleaned_data, languages = clean_data(all_samples)

df = pd.DataFrame()
df['language'] = languages
df['data'] = cleaned_data

df

label_enc = LabelEncoder()
df['language_label'] = label_enc.fit_transform(df['language'])

df.head()

label_enc.classes_

out_file = open("output.txt","w")

#create models
def create_models():
    models = {}
    models['LinearSVC'] = LinearSVC()
    models['LogisticRegression'] = LogisticRegression()
    models['RandomForestClassifier'] = RandomForestClassifier()
    models['DecisionTreeClassifier'] = DecisionTreeClassifier()
    models['MultinomialNB'] = MultinomialNB()
    return models

# shuffle and split dataset
X_input, y_input = shuffle(df['data'], df['language_label'], random_state=7)

X_train, X_test, y_train, y_test = train_test_split(X_input, y_input, test_size=0.7)

# function to calculate accuracy
def calculate_accuracy(actual_y, predicted_y, model_name, train_time, predict_time):
    print('Model Name: ' + model_name, file=out_file)
    print('Train time: ', round(train_time, 2), file=out_file)
    print('Predict time: ', round(predict_time, 2), file=out_file)
    print('Model Accuracy: {:.4f}'.format(accuracy_score(actual_y, predicted_y)), file=out_file)
    print('', file=out_file)
    print(classification_report(actual_y, predicted_y, digits=4), file=out_file)
    print("=======================================================", file=out_file)

def test_models(X_train, y_train, X_test, y_test, models):

    
    trained_models = {}
    
    vectorizer = FeatureUnion([('tfidf_vect', TfidfVectorizer())])
    
    X_train = vectorizer.fit_transform(X_train)
    X_test = vectorizer.transform(X_test)
    
    for key in models:
        model_name = key
        model = models[key]
        t1 = time.time()
        model.fit(X_train, y_train)
        t2 = time.time()
        predicted_y = model.predict(X_test)
        t3 = time.time()
        
        calculate_accuracy(y_test, predicted_y, model_name, t2 - t1, t3 - t2)        
        trained_models[model_name] = model
        
    return (trained_models, vectorizer)

models = create_models()
trained_models, fitted_vectorizer = test_models(X_train, y_train, X_test, y_test, models)

"""Saving the models"""

from sklearn.externals import joblib

for key in models:
  model_name = key
  model = models[key]
  joblib.dump(model, model_name+'.pkl')

out_file.close()

"""Load the saved model"""

ld_model_name = 'LogisticRegression.pkl'

log_reg = joblib.load(ld_model_name)

